{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Jeopardy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is slightly different than others you have encountered thus far. Instead of a step-by-step tutorial, this project contains a series of open-ended requirements which describe the project you'll be building. There are many possible ways to correctly fulfill all of these requirements, and you should expect to use the internet, Codecademy, and/or other resources when you encounter a problem that you cannot easily solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work to write several functions that investigate a dataset of _Jeopardy!_ questions and answers. Filter the dataset for topics that you're interested in, compute the average difficulty of those questions, and train to become the next Jeopardy champion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete this project, you should have completed the Pandas lessons in the <a href=\"https://www.codecademy.com/learn/paths/analyze-data-with-python\">Analyze Data with Python Skill Path</a>. You can also find those lessons in the <a href=\"https://www.codecademy.com/learn/data-processing-pandas\">Data Analysis with Pandas course</a> or the <a href=\"https://www.codecademy.com/learn/paths/data-science/\">Data Scientist Career Path</a>.\n",
    "\n",
    "Finally, the <a href=\"https://www.codecademy.com/learn/practical-data-cleaning\">Practical Data Cleaning</a> course may also be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We've provided a csv file containing data about the game show _Jeopardy!_ in a file named `jeopardy.csv`. Load the data into a DataFrame and investigate its contents. Try to print out specific columns.\n",
    "\n",
    "   Note that in order to make this project as \"real-world\" as possible, we haven't modified the data at all - we're giving it to you exactly how we found it. As a result, this data isn't as \"clean\" as the datasets you normally find on Codecademy. More specifically, there's something odd about the column names. After you figure out the problem with the column names, you may want to rename them to make your life easier for the rest of the project.\n",
    "   \n",
    "   In order to display the full contents of a column, we've added this line of code for you:\n",
    "   \n",
    "   ```py\n",
    "   pd.set_option('display.max_colwidth', None)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                                                                                      Question  \\\n",
      "0             For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory   \n",
      "1  No. 2: 1912 Olympian; football star at Carlisle Indian School; 6 MLB seasons with the Reds, Giants & Braves   \n",
      "2                     The city of Yuma in this state has a record average of 4,055 hours of sunshine each year   \n",
      "3                         In 1963, live on \"The Art Linkletter Show\", this company served its billionth burger   \n",
      "4     Signer of the Dec. of Indep., framer of the Constitution of Mass., second President of the United States   \n",
      "\n",
      "       Answer  \n",
      "0  Copernicus  \n",
      "1  Jim Thorpe  \n",
      "2     Arizona  \n",
      "3  McDonald's  \n",
      "4  John Adams  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"jeopardy.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['show_number', 'air_date', 'round', 'category', 'value', 'question', 'answer']\n"
     ]
    }
   ],
   "source": [
    "data.rename(columns={\"Show Number\": \"show_number\", \" Air Date\": \"air_date\", \" Round\": \"round\", \" Category\": \"category\", \" Value\": \"value\", \" Question\": \"question\", \" Answer\": \"answer\"}, inplace = True)\n",
    "columns = [column for column in data.columns]\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function that filters the dataset for questions that contains all of the words in a list of words. For example, when the list `[\"King\", \"England\"]` was passed to our function, the function returned a DataFrame of 49 rows. Every row had the strings `\"King\"` and `\"England\"` somewhere in its `\" Question\"`.\n",
    "\n",
    "   Test your function by printing out the column containing the question of each row of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df, words):\n",
    "    \n",
    "    filtered_df = df\n",
    "    for word in words:\n",
    "        filtered_df = filtered_df[filtered_df['question'].str.contains(word, case=False)]\n",
    "\n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_england = filter_dataframe(data, [\"King\", \"England\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Test your original function with a few different sets of words to try to find some ways your function breaks. Edit your function so it is more robust.\n",
    "\n",
    "   For example, think about capitalization. We probably want to find questions that contain the word `\"King\"` or `\"king\"`.\n",
    "   \n",
    "   You may also want to check to make sure you don't find rows that contain substrings of your given words. For example, our function found a question that didn't contain the word `\"king\"`, however it did contain the word `\"viking\"` &mdash; it found the `\"king\"` inside `\"viking\"`. Note that this also comes with some drawbacks &mdash; you would no longer find questions that contained words like `\"England's\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We may want to eventually compute aggregate statistics, like `.mean()` on the `\" Value\"` column. But right now, the values in that column are strings. Convert the`\" Value\"` column to floats. If you'd like to, you can create a new column with float values.\n",
    "\n",
    "   Now that you can filter the dataset of question, use your new column that contains the float values of each question to find the \"difficulty\" of certain topics. For example, what is the average value of questions that contain the word `\"King\"`?\n",
    "   \n",
    "   Make sure to use the dataset that contains the float values as the dataset you use in your filtering function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771.8833850722094\n"
     ]
    }
   ],
   "source": [
    "data[\"value\"] = data[\"value\"].apply(lambda value: float(value[1:].replace(',','')) if value != \"None\" else 0)\n",
    "\n",
    "# Filtering the dataset and finding the average value of those questions\n",
    "filtered = filter_dataframe(data, [\"King\"])\n",
    "print(filtered[\"value\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a function that returns the count of unique answers to all of the questions in a dataset. For example, after filtering the entire dataset to only questions containing the word `\"King\"`, we could then find all of the unique answers to those questions. The answer \"Henry VIII\" appeared 55 times and was the most common answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_answers(df: pd.DataFrame()):\n",
    "   return df.answer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_filtered = filter_dataframe(data, [\"King\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henry VIII                   55\n",
      "Solomon                      35\n",
      "Richard III                  33\n",
      "Louis XIV                    31\n",
      "David                        30\n",
      "                             ..\n",
      "cardiac (in card I acted)     1\n",
      "Henderson                     1\n",
      "Computer                      1\n",
      "Indians                       1\n",
      "work                          1\n",
      "Name: answer, Length: 5268, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_unique_answers = count_unique_answers(king_filtered)\n",
    "print(num_unique_answers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Explore from here! This is an incredibly rich dataset, and there are so many interesting things to discover. There are a few columns that we haven't even started looking at yet. Here are some ideas on ways to continue working with this data:\n",
    "\n",
    " - Investigate the ways in which questions change over time by filtering by the date. How many questions from the 90s use the word `\"Computer\"` compared to questions from the 2000s?\n",
    " - Is there a connection between the round and the category? Are you more likely to find certain categories, like `\"Literature\"` in Single Jeopardy or Double Jeopardy?\n",
    " - Build a system to quiz yourself. Grab random questions, and use the <a href=\"https://docs.python.org/3/library/functions.html#input\">input</a> function to get a response from the user. Check to see if that response was right or wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the 'air_date' column to datetime\n",
    "data['air_date'] = pd.to_datetime(data['air_date'])\n",
    "\n",
    "# Create a Boolean mask for rows that meet the condition\n",
    "mask_nineties = (data['air_date'] > '1989-12-31') & (data['air_date'] < '2000-01-01')\n",
    "mask_twenties = (data['air_date'] > '1999-12-31') & (data['air_date'] < '2010-01-01')\n",
    "\n",
    "# Select the rows that meet the condition\n",
    "nineties = data.loc[mask_nineties]\n",
    "twenties = data.loc[mask_twenties]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_questions(df: pd.DataFrame()):\n",
    "   return df.question.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 98 questions mentioning \"computer\" in 90s.\n",
      "There were 268 questions mentioning \"computer\" in 2000s.\n",
      "That is a 273.47% increase!\n"
     ]
    }
   ],
   "source": [
    "nineties_count = count_questions(filter_dataframe(nineties, [\"Computer\"]))\n",
    "print(f\"There were {nineties_count} questions mentioning \\\"computer\\\" in 90s.\")\n",
    "twenties_count = count_questions(filter_dataframe(twenties, [\"Computer\"]))\n",
    "print(f\"There were {twenties_count} questions mentioning \\\"computer\\\" in 2000s.\")\n",
    "print(f\"That is a {round(twenties_count / nineties_count * 100, 2)}% increase!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8982d2adebcad13b36fd1a732aa63410c0394382daca7d35e46b55bc71113ffc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
